from time import clock_settime
from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy
from kuavo_train.utils.augmenter import (Augmenter,
                                        DeterministicAugmenterColor,
                                        DeterministicAugmenterGeo4Rgbds,
                                        crop_image,
                                        resize_image)
from torch import Tensor, nn
import torch
from collections import deque
from lerobot.constants import ACTION, OBS_ENV_STATE, OBS_IMAGES, OBS_STATE
from kuavo_train.wrapper.DiffusionConfigWrapper import CustomDiffusionConfigWrapper
from lerobot.policies.utils import (
    get_device_from_parameters,
    get_dtype_from_parameters,
    get_output_shape,
    populate_queues,
)
from kuavo_train.wrapper.DiffusionModelWrapper import CustomDiffusionModelWrapper


class CustomDiffusionPolicyWrapper(DiffusionPolicy):
    def __init__(self,         
                 config: CustomDiffusionConfigWrapper,
                 dataset_stats: dict[str, dict[str, Tensor]] | None = None,
    ):
        super().__init__(config, dataset_stats)
        self.augmenter = Augmenter(config)
        self.diffusion = CustomDiffusionModelWrapper(config)


    def reset(self):
        """Clear observation and action queues. Should be called on `env.reset()`"""
        self._queues = {
            "observation.state": deque(maxlen=self.config.n_obs_steps),
            "action": deque(maxlen=self.config.n_action_steps),
        }
        if self.config.rgb_image_features:
            self._queues["observation.images"] = deque(maxlen=self.config.n_obs_steps)
        if self.config.env_state_feature:
            self._queues["observation.environment_state"] = deque(maxlen=self.config.n_obs_steps)

    def select_action(self, batch: dict[str, Tensor]) -> Tensor:
        """Select a single action given environment observations.

        This method handles caching a history of observations and an action trajectory generated by the
        underlying diffusion model. Here's how it works:
          - `n_obs_steps` steps worth of observations are cached (for the first steps, the observation is
            copied `n_obs_steps` times to fill the cache).
          - The diffusion model generates `horizon` steps worth of actions.
          - `n_action_steps` worth of actions are actually kept for execution, starting from the current step.
        Schematically this looks like:
            ----------------------------------------------------------------------------------------------
            (legend: o = n_obs_steps, h = horizon, a = n_action_steps)
            |timestep            | n-o+1 | n-o+2 | ..... | n     | ..... | n+a-1 | n+a   | ..... | n-o+h |
            |observation is used | YES   | YES   | YES   | YES   | NO    | NO    | NO    | NO    | NO    |
            |action is generated | YES   | YES   | YES   | YES   | YES   | YES   | YES   | YES   | YES   |
            |action is used      | NO    | NO    | NO    | YES   | YES   | YES   | NO    | NO    | NO    |
            ----------------------------------------------------------------------------------------------
        Note that this means we require: `n_action_steps <= horizon - n_obs_steps + 1`. Also, note that
        "horizon" may not the best name to describe what the variable actually means, because this period is
        actually measured from the first observation which (if `n_obs_steps` > 1) happened in the past.
        """
        # 与环境交互时无需图像增强
        if ACTION in batch:
            batch.pop(ACTION)

        batch = self.normalize_inputs(batch)

        if self.config.rgb_image_features:
            batch = dict(batch)  # shallow copy so that adding a key doesn't modify the original

            # Add rgb augmentation
            for key in self.config.rgb_image_features:
                if self.config.depth_image_features:
                    batch[key] = torch.cat([batch[key],batch[key+'_depth'][:,:,0,:,:]],dim=-3)
                random_crop = self.config.crop_is_random and self.training
                batch[key] = crop_image(batch[key],self.augmenter.crop_shape,random_crop=random_crop)
                batch[key] = resize_image(batch[key],self.augmenter.resize_shape)

            batch[OBS_IMAGES] = torch.stack(
                [batch[key] for key in self.config.rgb_image_features], dim=-4
            )
        # Note: It's important that this happens after stacking the images into a single key.
        self._queues = populate_queues(self._queues, batch)

        if len(self._queues[ACTION]) == 0:
            actions = self.predict_action_chunk(batch)
            self._queues[ACTION].extend(actions.transpose(0, 1))

        action = self._queues[ACTION].popleft()
        return action

    def forward(self, batch: dict[str, Tensor]) -> tuple[Tensor, None]:
        """Run the batch through the model and compute the loss for training or validation."""
        for key in self.config.rgb_image_features:
            if self.config.RGB_Augmentation:
                self.augmenter.RGB_Augmenter.set_random_params()
                batch[key] = self.augmenter.RGB_Augmenter.apply_augment_sequence(batch[key])
        batch = self.normalize_inputs(batch)
        if self.config.rgb_image_features:
            batch = dict(batch)  # shallow copy so that adding a key doesn't modify the original
            # rgb augmentation
            for key in self.config.rgb_image_features:
                if self.config.depth_image_features:
                    batch[key] = torch.cat([batch[key],batch[key+'_depth'][:,:,0,:,:]],dim=-3)
                random_crop = self.config.crop_is_random and self.training
                batch[key] = crop_image(batch[key],self.augmenter.crop_shape,random_crop=random_crop)
                batch[key] = resize_image(batch[key],self.augmenter.resize_shape)

            batch[OBS_IMAGES] = torch.stack(
                [batch[key] for key in self.config.rgb_image_features], dim=-4
            )
        # print(f"batch['action'][0,0]: {batch['action'][0,0]}")
        batch = self.normalize_targets(batch)
        # print(f"batch['action'][0,0]: {batch['action'][0,0]}")
        loss = self.diffusion.compute_loss(batch)
        # no output_dict so returning None
        return loss, None